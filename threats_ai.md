| Название угрозы [русский перевод] | Техническое описание | Описание для нетехнических специалистов | Возникающие риски | Простой пример | Меры по предотвращению |
|---|--------|---------|-------|------|-------|
| Атака с подменой данных (Data Poisoning) | Злоумышленники модифицируют обучающие данные модели, чтобы она обучалась на неверной информации. | Вредоносные данные могут повредить работу модели, заставляя ее давать неправильные результаты. | Ухудшение качества модели, ведущее к неверным прогнозам или классификациям. | Злоумышленник добавляет неправильные метки к данным, чтобы повлиять на выводы модели. | Реализуйте фильтрацию и валидацию данных перед их использованием для обучения. |
| Атака с обходом модели (Model Evasion) | Злоумышленники изменяют входные данные, чтобы обойти защитные механизмы модели. | Изменение данных позволяет обмануть модель, чтобы она не распознала угрозу или атаку. | Невозможность обнаружить вредоносные действия или аномалии, что может привести к утечке данных. | Злоумышленник изменяет изображение, чтобы обмануть систему распознавания лиц. | Постоянно обновляйте модель и используйте методики противодействия, такие как adversarial training. |
| Атака с извлечением модели (Model Extraction) | Злоумышленники пытаются воспроизвести модель, анализируя её поведение на различных входных данных. | Копирование модели может позволить злоумышленникам использовать её без авторизации или доступа к исходному коду. | Утрата интеллектуальной собственности и снижение конкурентоспособности. | Злоумышленник использует API модели, чтобы собрать достаточно информации для её копирования. | Ограничьте доступ к API и используйте методы аутентификации и авторизации. |
| Уязвимости в алгоритмах (Algorithmic Bias) | Модели могут неосознанно отражать предвзятости, присутствующие в обучающих данных, что приводит к несправедливым выводам. | Если данные, на которых обучалась модель, были предвзятыми, это может привести к дискриминации определенных групп. | Ущерб репутации, юридические последствия и социальные последствия. | Модель распознавания лиц хуже работает для определенных расовых групп из-за предвзятости в данных. | Проведите тестирование и аудит модели на предвзятость, а также используйте сбалансированные данные. |
| Уязвимости в безопасности данных (Data Leakage) | Неосторожное обращение с данными может привести к их утечке, что ставит под угрозу конфиденциальность пользователей. | Если данные пользователей не защищены, злоумышленники могут получить к ним доступ. | Утрата конфиденциальной информации, нарушение законов о защите данных. | Модель случайно раскрывает данные пользователей в своих выводах или прогнозах. | Используйте методы шифрования данных и ограничения доступа к чувствительной информации. |
| Атака с использованием запроса (Query Injection) | Злоумышленники могут манипулировать входными данными, чтобы получить доступ к внутренним данным модели. | Если входные данные не фильтруются, злоумышленники могут получить доступ к конфиденциальной информации. | Утечка данных, возможность выполнения произвольного кода. | Злоумышленник вводит вредоносные команды в текстовые поля, чтобы получить доступ к данным. | Реализуйте валидацию и фильтрацию входных данных, чтобы предотвратить такие атаки. |
| Атака с использованием обратной связи (Feedback Attack) | Злоумышленники могут манипулировать системой обратной связи, чтобы повлиять на будущие прогнозы модели. | Злоумышленники могут вводить ложные данные в систему, чтобы изменить поведение модели. | Ухудшение качества прогнозов и возможность манипуляции результатами. | Злоумышленник вводит ложные отзывы о продукте, чтобы улучшить его рейтинг. | Используйте механизмы аутентификации и валидации для систем обратной связи. |
| Уязвимости в доступе к данным (Access Control Vulnerabilities) | Неправильная настройка контроля доступа может позволить несанкционированным пользователям получать доступ к данным или функциям модели. | Если доступ к данным не ограничен, злоумышленники могут использовать их для своих целей. | Утечка конфиденциальной информации и возможность манипуляции данными. | Злоумышленник получает доступ к API, который не защищен и позволяет извлекать данные. | Реализуйте строгие механизмы контроля доступа, используя аутентификацию и авторизацию. |
| Небезопасная десериализация (Insecure Deserialization) | Десериализация данных из ненадежных источников может привести к выполнению произвольного кода. | Если приложение принимает данные без проверки, злоумышленник может отправить вредоносные данные, которые приведут к атакам. | Исполнение вредоносного кода, что может привести к утечке данных или повреждению устройства. | Приложение десериализует данные, которые были изменены злоумышленником, и выполняет их. | Используйте безопасные форматы для передачи данных и избегайте десериализации данных из ненадежных источников. |
| Неправильная обработка исключений (Improper Exception Handling) | Необработанные исключения могут раскрыть информацию о внутренней архитектуре приложения. | Если приложение не обрабатывает ошибки должным образом, злоумышленники могут узнать о его уязвимостях. | Утечка информации о внутренних механизмах приложения, что может способствовать атакам. | Приложение выводит стек ошибок в логи, показывая чувствительную информацию. | Используйте безопасные механизмы обработки исключений и отключите вывод отладочной информации в продакшене. |
| Уязвимости в обучающих данных (Training Data Vulnerabilities) | Неправильное использование или обработка обучающих данных может повлиять на эффективность модели. | Если обучающие данные не являются репрезентативными или содержат ошибки, это может привести к снижению качества модели. | Понижение точности модели и возможность получения неверных результатов. | Модель обучается на данных, содержащих много ошибок или недостающих значений. | Проводите регулярный аудит и предобработку данных перед обучением модели. |
